---
permalink: /
title: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I’m **Ze Rong (戎泽)** — an undergraduate in Computer Science & Technology at **Nantong University**.  
My work sits at the intersection of **medical imaging**, **multimodal learning**, and **sports analytics**. I’m particularly interested in:

- **Frequency-domain representation learning** for robust medical image understanding  
- **Vision–language alignment** and evidence-grounded reasoning for clinical AI  
- **Graph-based tactics modeling** for soccer using tracking, audio, and commentary  
- **Non-invasive brain decoding** (fMRI/MEG → language/semantics)  
- **Federated learning & unlearning** with efficient, economics-inspired training

I enjoy building full pipelines—**from data engineering to models to deployment**—and writing clean, reproducible research code.

---

## News
- **2025** — *FaRMamba* accepted to **ICONIP 2025** (medical image segmentation with frequency learning + reconstruction-aided Mamba).  
- Ongoing — EchoGNN for **emotion-aware tactical analysis** on soccer broadcast + tracking.  
- Ongoing — **SMN4Lang**-based semantic decoding reproduction, with extensions to frequency-aligned modules.

---

## Selected Projects
**FaRMamba** — Frequency-based & Reconstruction-aided Mamba for Medical Segmentation  
- Frequency-domain modules + auxiliary reconstruction to improve Dice/robustness.  
- *Status:* accepted to ICONIP 2025.  
- Code/Preprint: *[link]*

**EchoGNN (sports analytics)** — Emotion-aware spatio-temporal graph for counter-attack modeling  
- Fuse player/ball tracks, audio arousal (CLAP/whisper), and commentary semantics; ST-GNN with FiLM.  
- *Status:* in progress.  
- Code: *[link]*

**FIRM (VI-ReID)** — Fusion-Injected Residual Memory for cross-modal person re-identification  
- Token-level alignment + hierarchical fidelity modeling.  
- *Status:* manuscript.  
- Preprint: *[link]*

**BCI Semantic Decoding** — Reproducing & extending HuthLab pipeline  
- ROI-aware features, ridge baselines, frequency-aligned enhancements.  
- *Status:* in progress.  
- Notes/Code: *[link]*

---

## Publications & Manuscripts
- **FaRMamba** — ICONIP 2025. *Frequency-based learning & reconstruction-aided Mamba for medical segmentation.*  
  [paper](*link*) · [code](*link*)
- **MSC-LSAM** — *Journal of Data Acquisition and Processing*, 2025 (planned/accepted as per your records).  
  [paper](*link*)
- More works in preparation on multimodal medical AI, sports analytics, and BCI decoding.

> A compact, up-to-date list lives on **[Google Scholar]** and **[GitHub]**.

---

## Experience (highlights)
- **Nantong University** — Undergraduate researcher, AI & medical imaging lab (with Prof. Lei Ma).  
- Collaborations with **football analytics** groups on SkillCorner OpenData.  
- Hands-on federated learning & unlearning pipelines; reproducible experiments on 3090 GPUs.

---

## Open-source & Engineering
- Clean, documented code; reproducible configs; data converters (kloppy→polars), evaluation scripts, and figure generation.  
- Tooling: PyTorch · TensorFlow (Spektral) · OpenMMLab · Whisper/CLAP · Polars · JAX (occasional) · Docker.

---

## Awards (selected)
- **China Robot and AI Competition (CRAIC) 2025 — National Second Prize**  
- **CRAIC 2024 — National First Prize**

---

## Looking ahead
I’m seeking opportunities to **pursue a PhD** in medical AI / multimodal reasoning, with strong emphasis on **frequency-domain learning, VLM alignment, and clinically reliable models**. I value teams that care about **reproducibility, transparency, and real clinical impact**.

If our interests align, let’s talk.

- Email: <your_email@example.com>  
- GitHub: [github.com/ZeRong7777](https://github.com/ZeRong7777) *(or your active handle)*  
- Google Scholar: [scholar profile](https://scholar.google.com/citations?user=x8lRCGgAAAAJ)

---



